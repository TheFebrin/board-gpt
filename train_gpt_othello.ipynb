{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Othello-GPT and save to `ckpts`\n",
    "\n",
    "Use `jupyter nbconvert --execute --to notebook --allow-errors --ExecutePreprocessor.timeout=-1 train_gpt_othello.ipynb --inplace --output ckpts/checkpoint.ipynb` to run in background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make deterministic\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from data import get_othello\n",
    "from data.othello import permit, start_hands, OthelloBoardState, permit_reverse\n",
    "from mingpt.dataset import CharDataset\n",
    "from mingpt.utils import sample\n",
    "from mingpt.model import GPT, GPTConfig\n",
    "from mingpt.trainer import Trainer, TrainerConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_or_championship = False  # True for training on the synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 326/327 (qualified/total) sequences from liveothello2010.pgn\n",
      "Loaded 303/303 (qualified/total) sequences from liveothello2011.pgn\n",
      "Loaded 674/674 (qualified/total) sequences from liveothello2012.pgn\n",
      "Loaded 413/413 (qualified/total) sequences from liveothello2013.pgn\n",
      "Loaded 406/407 (qualified/total) sequences from liveothello2014.pgn\n",
      "Loaded 487/487 (qualified/total) sequences from liveothello2015.pgn\n",
      "Loaded 644/645 (qualified/total) sequences from liveothello2016.pgn\n",
      "Loaded 892/893 (qualified/total) sequences from liveothello2017.pgn\n",
      "Loaded 850/850 (qualified/total) sequences from liveothello2018.pgn\n",
      "Loaded 950/950 (qualified/total) sequences from liveothello2019.pgn\n",
      "Loaded 862/862 (qualified/total) sequences from liveothello2020.pgn\n",
      "Loaded 465/465 (qualified/total) sequences from liveothello2021.pgn\n",
      "Loaded 12/12 (qualified/total) sequences from WTHOR-1977.pgn\n",
      "Loaded 8/8 (qualified/total) sequences from WTHOR-1978.pgn\n",
      "Loaded 11/11 (qualified/total) sequences from WTHOR-1979.pgn\n",
      "Loaded 160/160 (qualified/total) sequences from WTHOR-1980.pgn\n",
      "Loaded 153/153 (qualified/total) sequences from WTHOR-1981.pgn\n",
      "Loaded 110/110 (qualified/total) sequences from WTHOR-1982.pgn\n",
      "Loaded 199/199 (qualified/total) sequences from WTHOR-1983.pgn\n",
      "Loaded 587/587 (qualified/total) sequences from WTHOR-1984.pgn\n",
      "Loaded 954/954 (qualified/total) sequences from WTHOR-1985.pgn\n",
      "Loaded 1440/1440 (qualified/total) sequences from WTHOR-1986.pgn\n",
      "Loaded 1386/1386 (qualified/total) sequences from WTHOR-1987.pgn\n",
      "Loaded 1823/1823 (qualified/total) sequences from WTHOR-1988.pgn\n",
      "Loaded 2186/2186 (qualified/total) sequences from WTHOR-1989.pgn\n",
      "Loaded 2986/2986 (qualified/total) sequences from WTHOR-1990.pgn\n",
      "Loaded 3152/3152 (qualified/total) sequences from WTHOR-1991.pgn\n",
      "Loaded 3347/3347 (qualified/total) sequences from WTHOR-1992.pgn\n",
      "Loaded 3484/3484 (qualified/total) sequences from WTHOR-1993.pgn\n",
      "Loaded 4343/4343 (qualified/total) sequences from WTHOR-1994.pgn\n",
      "Loaded 4968/4968 (qualified/total) sequences from WTHOR-1995.pgn\n",
      "Loaded 5852/5852 (qualified/total) sequences from WTHOR-1996.pgn\n",
      "Loaded 7681/7681 (qualified/total) sequences from WTHOR-1997.pgn\n",
      "Loaded 8077/8077 (qualified/total) sequences from WTHOR-1998.pgn\n",
      "Loaded 7685/7685 (qualified/total) sequences from WTHOR-1999.pgn\n",
      "Loaded 4253/4253 (qualified/total) sequences from WTHOR-2000.pgn\n",
      "Loaded 5575/5575 (qualified/total) sequences from WTHOR-2001.pgn\n",
      "Loaded 5423/5423 (qualified/total) sequences from WTHOR-2002.pgn\n",
      "Loaded 3858/3858 (qualified/total) sequences from WTHOR-2003.pgn\n",
      "Loaded 9113/9113 (qualified/total) sequences from WTHOR-2004.pgn\n",
      "Loaded 4199/4199 (qualified/total) sequences from WTHOR-2005.pgn\n",
      "Loaded 2942/2942 (qualified/total) sequences from WTHOR-2006.pgn\n",
      "Loaded 2478/2478 (qualified/total) sequences from WTHOR-2007.pgn\n",
      "Loaded 2232/2232 (qualified/total) sequences from WTHOR-2008.pgn\n",
      "Loaded 4348/4348 (qualified/total) sequences from WTHOR-2009.pgn\n",
      "Loaded 2172/2172 (qualified/total) sequences from WTHOR-2010.pgn\n",
      "Loaded 1891/1891 (qualified/total) sequences from WTHOR-2011.pgn\n",
      "Loaded 2208/2208 (qualified/total) sequences from WTHOR-2012.pgn\n",
      "Loaded 2396/2396 (qualified/total) sequences from WTHOR-2013.pgn\n",
      "Loaded 1817/1817 (qualified/total) sequences from WTHOR-2014.pgn\n",
      "Loaded 1789/1789 (qualified/total) sequences from WTHOR-2015.pgn\n",
      "Loaded 2013/2013 (qualified/total) sequences from WTHOR-2016.pgn\n",
      "Loaded 2449/2449 (qualified/total) sequences from WTHOR-2017.pgn\n",
      "Loaded 2429/2429 (qualified/total) sequences from WTHOR-2018.pgn\n",
      "Loaded 1127/1127 (qualified/total) sequences from WTHOR-2019.pgn\n",
      "Dataset created has 132588 sequences, 61 unique words.\n"
     ]
    }
   ],
   "source": [
    "# We run get_othello with data_root = \"data/othello_championship/\"\n",
    "othello = get_othello(ood_num=-1, data_root=None if synthetic_or_championship else \"data/othello_championship\", wthor=True)\n",
    "train_dataset = CharDataset(othello)\n",
    "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size, n_layer=2, n_head=8, n_embd=80)\n",
    "model = GPT(mconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_epochs = 0\n",
    "# # initialize a trainer instance and kick off training\n",
    "# t_start = time.strftime(\"_%Y%m%d_%H%M%S\")\n",
    "# tconf = TrainerConfig(\n",
    "#     max_epochs=max_epochs, \n",
    "#     batch_size=10*1,  # assuming 8 GPU's\n",
    "#     learning_rate=5e-4,\n",
    "#     lr_decay=True, \n",
    "#     warmup_tokens=len(train_dataset)*train_dataset.block_size*5, \n",
    "#     final_tokens=len(train_dataset)*train_dataset.block_size*max_epochs,\n",
    "#     num_workers=0, \n",
    "#     ckpt_path=f\"./ckpts/gpt_at{t_start}.ckpt\", \n",
    "# )\n",
    "# trainer = Trainer(model, train_dataset, None, tconf)\n",
    "# device = trainer.device\n",
    "# print(t_start)\n",
    "# trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or load trained model from `ckpts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_res = model.load_state_dict(torch.load(\"./ckpts/gpt_synthetic.ckpt\" if synthetic_or_championship else \"./ckpts/gpt_championship.ckpt\"))\n",
    "# if torch.cuda.is_available():\n",
    "#     device = torch.cuda.current_device()\n",
    "#     model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_res = model.load_state_dict(torch.load(\"./ckpts/gpt_at_20230529_101657.ckpt\"))\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.current_device()\n",
    "    model = model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate it: for what percentage of all partial games in validation set, the top-1 prediction is legal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# othello = get_othello(ood_num=1, data_root=None, wthor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(othello.sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading synthetic dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mem Used: 4.117 GB: 100%|██████████| 64/64 [00:19<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deduplicating...\n",
      "Deduplicating finished with 6399176 games left\n",
      "Using 800 for training, 6398376 for validation\n"
     ]
    }
   ],
   "source": [
    "if not synthetic_or_championship:  # for GPT trained on both datasets, use the validation set of synthetic for validation\n",
    "    othello = get_othello(ood_num=-1, data_root=None, wthor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# othello = get_othello(ood_num=1, data_root=None, wthor=True, train_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90.04% pass rate: 53111/58989 among all searched nodes: 100%|██████████| 1000/1000 [06:44<00:00,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.04% pass rate: 53111/58989 among all searched nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_nodes = 0\n",
    "success_nodes = 0\n",
    "\n",
    "bar = tqdm(othello.val[:1000])\n",
    "for whole_game in bar:\n",
    "    length_of_whole_game = len(whole_game)\n",
    "    # print(\"WHOLE GAME: \", whole_game, \"\\n\")\n",
    "    for length_of_partial_game in range(1, length_of_whole_game):\n",
    "        total_nodes += 1\n",
    "        context = whole_game[:length_of_partial_game]\n",
    "        # print(\"CONTEXT:\", context)\n",
    "        x = torch.tensor([train_dataset.stoi[s] for s in context], dtype=torch.long)[None, ...].to(device)\n",
    "        y = sample(model, x, 1, temperature=1.0)[0]\n",
    "        # print(\"Using {}. Prediction: {}\".format(x, y))\n",
    "        completion = [train_dataset.itos[int(i)] for i in y if i != -1]\n",
    "        # print()\n",
    "        try:\n",
    "            OthelloBoardState().update(completion, prt=False)\n",
    "        except Exception:\n",
    "#             fail_nodes.append([permit_reverse(_) for _ in context])\n",
    "            pass\n",
    "        else:\n",
    "            success_nodes += 1\n",
    "    bar.set_description(f\"{success_nodes/total_nodes*100:.2f}% pass rate: {success_nodes}/{total_nodes} among all searched nodes\")\n",
    "# # print(total_nodes)\n",
    "print(f\"{success_nodes/total_nodes*100:.2f}% pass rate: {success_nodes}/{total_nodes} among all searched nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09964569665530865"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - success_nodes/total_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
