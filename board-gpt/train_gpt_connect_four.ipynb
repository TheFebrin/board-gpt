{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Othello-GPT and save to `ckpts`\n",
    "\n",
    "Use `jupyter nbconvert --execute --to notebook --allow-errors --ExecutePreprocessor.timeout=-1 train_gpt_othello.ipynb --inplace --output ckpts/checkpoint.ipynb` to run in background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make deterministic\n",
    "# from mingpt.utils import set_seed\n",
    "# set_seed(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from connect_four.connect_four import ConnectFour\n",
    "from connect_four.connect_four_dataset import ConnectFourDataset, CharConnectFourDataset, DatasetPreprocessingConfig\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from mingpt.utils import sample\n",
    "from mingpt.model import GPT, GPTConfig\n",
    "from mingpt.trainer import Trainer, TrainerConfig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = ConnectFourDataset(\n",
    "#     data_size=110000,\n",
    "#     train_size=110000,\n",
    "#     rows_count=6,\n",
    "#     columns_count=7\n",
    "# )\n",
    "\n",
    "# with open(\"connect_four/dataset/dataset_6x7_110000.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(dataset.sequences, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the existing dataset from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"connect_four/dataset/dataset_minmax_123_7383.pkl\", \"rb\") as f:\n",
    "    game_transcriptions = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created has 7138 sequences, 8 unique words.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-100, 0, 1, 2, 3, 4, 5, 6],\n",
       " DatasetPreprocessingConfig(to_model_repr={-100: 0, 0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7}, from_model_repr={0: -100, 1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6}, block_size=41, vocab_size=8),\n",
       " 42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_data = ConnectFourDataset(data_size=0, train_size=7138, games_to_use=game_transcriptions)\n",
    "char_cf_dataset = CharConnectFourDataset(cf_data)\n",
    "char_cf_dataset.chars, char_cf_dataset.config, char_cf_dataset.max_len"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize model, and optionally train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.cuda.current_device()\n",
    "mconf = GPTConfig(char_cf_dataset.config.vocab_size, char_cf_dataset.config.block_size, n_layer=2, n_head=8, n_embd=80)\n",
    "model = GPT(mconf).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 713: train loss 1.19634. lr 1.000000e-04: 100%|██████████| 714/714 [00:08<00:00, 87.30it/s]\n",
      "epoch 2 iter 713: train loss 0.73517. lr 2.000000e-04: 100%|██████████| 714/714 [00:08<00:00, 86.10it/s]\n",
      "epoch 3 iter 713: train loss 0.74214. lr 3.000000e-04: 100%|██████████| 714/714 [00:08<00:00, 85.68it/s]\n",
      "epoch 4 iter 713: train loss 0.51858. lr 4.000000e-04: 100%|██████████| 714/714 [00:08<00:00, 86.99it/s]\n",
      "epoch 5 iter 713: train loss 0.47359. lr 5.000000e-04: 100%|██████████| 714/714 [00:08<00:00, 87.04it/s]\n",
      "epoch 6 iter 713: train loss 0.59881. lr 4.945369e-04: 100%|██████████| 714/714 [00:08<00:00, 87.66it/s]\n",
      "epoch 7 iter 713: train loss 0.61803. lr 4.783864e-04: 100%|██████████| 714/714 [00:08<00:00, 87.97it/s]\n",
      "epoch 8 iter 713: train loss 0.55427. lr 4.522542e-04: 100%|██████████| 714/714 [00:08<00:00, 88.25it/s]\n",
      "epoch 9 iter 713: train loss 0.42229. lr 4.172827e-04: 100%|██████████| 714/714 [00:08<00:00, 87.39it/s]\n",
      "epoch 10 iter 713: train loss 0.53981. lr 3.750000e-04: 100%|██████████| 714/714 [00:08<00:00, 80.98it/s]\n",
      "epoch 11 iter 713: train loss 0.47413. lr 3.272542e-04: 100%|██████████| 714/714 [00:09<00:00, 77.65it/s]\n",
      "epoch 12 iter 713: train loss 0.46977. lr 2.761321e-04: 100%|██████████| 714/714 [00:09<00:00, 75.48it/s]\n",
      "epoch 13 iter 713: train loss 0.42893. lr 2.238679e-04: 100%|██████████| 714/714 [00:09<00:00, 77.91it/s]\n",
      "epoch 14 iter 713: train loss 0.35459. lr 1.727458e-04: 100%|██████████| 714/714 [00:09<00:00, 77.05it/s]\n",
      "epoch 15 iter 713: train loss 0.46860. lr 1.250000e-04: 100%|██████████| 714/714 [00:08<00:00, 81.54it/s]\n",
      "epoch 16 iter 713: train loss 0.40262. lr 8.271735e-05: 100%|██████████| 714/714 [00:08<00:00, 85.28it/s]\n",
      "epoch 17 iter 713: train loss 0.40758. lr 5.000000e-05: 100%|██████████| 714/714 [00:08<00:00, 79.89it/s]\n",
      "epoch 18 iter 713: train loss 0.42165. lr 5.000000e-05: 100%|██████████| 714/714 [00:09<00:00, 75.25it/s]\n",
      "epoch 19 iter 713: train loss 0.35978. lr 5.000000e-05: 100%|██████████| 714/714 [00:08<00:00, 85.02it/s]\n",
      "epoch 20 iter 713: train loss 0.61132. lr 5.000000e-05: 100%|██████████| 714/714 [00:08<00:00, 86.92it/s]\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 20\n",
    "# initialize a trainer instance and kick off training\n",
    "t_start = time.strftime(\"_%Y%m%d_%H%M%S\")\n",
    "tconf = TrainerConfig(\n",
    "    max_epochs=max_epochs, \n",
    "    batch_size=10,\n",
    "    learning_rate=5e-4,\n",
    "    lr_decay=True, \n",
    "    warmup_tokens=len(char_cf_dataset)*char_cf_dataset.config.block_size*5, \n",
    "    final_tokens=len(char_cf_dataset)*char_cf_dataset.config.block_size*max_epochs,\n",
    "    num_workers=0, \n",
    "    ckpt_path=f\"./ckpts/minmax_models/gpt_at{t_start}.ckpt\", \n",
    ")\n",
    "trainer = Trainer(model, char_cf_dataset, None, tconf)\n",
    "device = trainer.device\n",
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained model from `ckpts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_res = model.load_state_dict(torch.load(\"./ckpts/gpt_at_20230618_093325.ckpt\"))\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.current_device()\n",
    "    model = model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate it: for what percentage of all partial games in validation set, the top-1 prediction is legal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(\n",
    "        dataset: ConnectFourDataset,\n",
    "        dataset_config: DatasetPreprocessingConfig,\n",
    "        model: GPT\n",
    "):\n",
    "    total_nodes = 0\n",
    "    success_nodes = 0\n",
    "\n",
    "    bar = tqdm(dataset.valid)\n",
    "    for whole_game in bar:\n",
    "        length_of_whole_game = len(whole_game)\n",
    "        for length_of_partial_game in range(1, length_of_whole_game):\n",
    "            total_nodes += 1\n",
    "            context = whole_game[:length_of_partial_game]\n",
    "            x = torch.tensor([dataset_config.to_model_repr[s] for s in context], dtype=torch.long)[None, ...].to(device)\n",
    "            y = sample(model, x, 1, temperature=1.0)[0]\n",
    "            completion = [dataset_config.from_model_repr[int(i)] for i in y if i != -1]\n",
    "            game_repr = ConnectFour()\n",
    "            piece = 1\n",
    "            for move in context:\n",
    "                game_repr.apply_move(piece, move)\n",
    "                piece = 2 if piece == 1 else 1\n",
    "            if game_repr.is_move_possible(completion[-1]):\n",
    "                success_nodes += 1\n",
    "        bar.set_description(f\"{success_nodes/total_nodes*100:.2f}% pass rate: {success_nodes}/{total_nodes} among all searched nodes\")\n",
    "    print(f\"{success_nodes/total_nodes*100:.2f}% pass rate: {success_nodes}/{total_nodes} among all searched nodes\")\n",
    "    return success_nodes/total_nodes*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99.97% pass rate: 9745/9748 among all searched nodes: 100%|██████████| 246/246 [00:47<00:00,  5.18it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.97% pass rate: 9745/9748 among all searched nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99.96922445629873"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_model(dataset=cf_data, dataset_config=char_cf_dataset.config, model=model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
